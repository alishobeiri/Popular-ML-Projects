Title,URL,Score,Date
"[P] 80% faster, 50% less memory, 0% loss in accuracy Llama finetuning","https://github.com/unslothai/unsloth
https://github.com/danielhanchen/hyperlearn
https://github.com/unslothai/unsloth/blob/main/README.md",204,2023-12-01 16:31:39
[D] Bitter Lesson and Tree of Thoughts - Are techniques like ToT examples of using search or are they ignoring the bitter lesson by encoding humanlike learning?,"https://arxiv.org/pdf/2309.15028.pdf
https://arxiv.org/pdf/2303.05510.pdf
https://arxiv.org/pdf/2305.10601.pdf",36,2023-12-02 13:23:42
