Title,URL,Score,Date
[D] The ML Papers That Rocked Our World (2020-2023),"https://arxiv.org/abs/2210.05189
https://arxiv.org/abs/2212.13345
https://arxiv.org/abs/2106.09685
https://arxiv.org/abs/2201.02177
https://arxiv.org/abs/2010.11929
https://arxiv.org/abs/2104.14294
https://arxiv.org/abs/2012.12877v2
https://arxiv.org/abs/2103.14030
https://arxiv.org/abs/2201.03545
https://arxiv.org/abs/2103.00020
https://arxiv.org/abs/2112.10752
https://arxiv.org/abs/2006.11239
https://arxiv.org/abs/2207.12598
https://arxiv.org/abs/2012.09841
https://arxiv.org/abs/2304.02643
https://arxiv.org/abs/2304.07193
https://arxiv.org/abs/2308.07037
https://arxiv.org/abs/2005.14165
https://arxiv.org/abs/2201.11903
https://arxiv.org/abs/2203.02155
https://arxiv.org/abs/2203.15556
https://arxiv.org/abs/2301.13688
https://arxiv.org/abs/2302.13971
https://arxiv.org/abs/2302.04761
https://arxiv.org/abs/2003.08934
https://github.com/dmarx/anthology-of-modern-ml",102,2023-09-14 13:50:27
[P] Llama2 inference in a single file of pure Mojo,"https://github.com/tairov/llama2.mojo
https://github.com/tairov/llama2.py
https://github.com/karpathy/llama2.c",59,2023-09-14 12:32:42
[D] We built Beam: An ultrafast serverless GPU runtime,https://github.com/slai-labs/get-beam/tree/main/examples,53,2023-09-13 14:06:50
[R] Efficient Memory Management for Large Language Model Serving with PagedAttention - UC Berkeley et al 2023 - 2-4x higher throughput than HuggingFace Transformers without requiring any model architecture changes!,"https://arxiv.org/abs/2309.06180
https://github.com/vllm-project/vllm",37,2023-09-13 19:55:42
