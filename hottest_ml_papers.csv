Title,URL,Score,Date
"[P] nanoT5 v2 - In ~16 hours on a single GPU, we reach similar performance to the model trained on 150x more data!",https://github.com/PiotrNawrot/nanoT5,95,2023-07-05 13:56:50
[R] LaVIN-lite: Training your own Multimodal Large Language Models on one single GPU with competitive performance! (Technical Details),https://github.com/artidoro/qlora,81,2023-07-04 17:23:45
[R] Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing,https://arxiv.org/abs//2306.17848,48,2023-07-03 18:01:58
[P] Nuggt: A LLM Agent that runs on Wizcoder-15B (4-bit Quantised). It's time to democratise LLM Agents,https://github.com/Nuggt-dev/Nuggt,44,2023-07-04 19:16:35
[D] When less is more in the hierarchical forecasting case.,"https://arxiv.org/abs/2305.07089)
https://github.com/Nixtla/hierarchicalforecast/tree/main/experiments/hierarchical_baselines",35,2023-07-03 18:22:41
