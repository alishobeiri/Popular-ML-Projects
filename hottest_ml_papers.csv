Title,URL,Score,Date
[R] Fine-Tuning Language Models with Just Forward Passes,"https://arxiv.org/abs/2305.17333
https://github.com/princeton-nlp/mezo",161,2023-05-31 09:03:27
[N] (Update: Code Released) Landmark Attention: Random-Access Infinite Context Length for Transformers,"https://arxiv.org/abs/2305.16300
https://github.com/epfml/landmark-attention",33,2023-05-31 08:56:37
