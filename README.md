| Title                                                                                                                         | URL                              |   Score | Date                |
|:------------------------------------------------------------------------------------------------------------------------------|:---------------------------------|--------:|:--------------------|
| [R][P] KV Cache is huge and bottlenecks LLM inference. We quantize them to 2bit in a finetuning-free + plug-and-play fashion. | https://arxiv.org/abs/2211.05102 |      52 | 2024-02-12 16:00:37 |
|                                                                                                                               | https://arxiv.org/abs/2309.06180 |         |                     |
|                                                                                                                               | https://arxiv.org/abs/2402.02750 |         |                     |
|                                                                                                                               | https://github.com/jy-yuan/KIVI  |         |                     |