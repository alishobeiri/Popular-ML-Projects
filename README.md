| Title                                                                                                                                                                                             | URL                                 |   Score | Date                |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------|--------:|:--------------------|
| [R] New paper shows that draws in LLM battles aren't what you think                                                                                                                               | https://arxiv.org/abs/2510.02306    |      29 | 2025-10-03 21:08:42 |
| [R] New paper: LLMs don't have privileged self knowledge, which means we can efficiently train a General Correctness Model to predict the correctness of multiple models. Surprising or expected? | https://arxiv.org/html/2509.24988v1 |      26 | 2025-10-03 03:52:19 |