| Title                                                                                                                                                        | URL                                      |   Score | Date                |
|:-------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------|--------:|:--------------------|
| [R][P] We compress any BF16 model to ~70% size during inference, while keeping the output LOSSLESS so that you can fit in more context or run larger models. | https://arxiv.org/abs/2504.11651         |     182 | 2025-04-25 15:55:34 |
|                                                                                                                                                              | https://github.com/LeanModels/DFloat11   |         |                     |
| [R] Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning                                                                        | https://github.com/going-doer/Paper2Code |      85 | 2025-04-25 16:43:05 |