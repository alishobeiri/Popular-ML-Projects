| Title                                                                                                                                                            | URL                                                      |   Score | Date                |
|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------|--------:|:--------------------|
| [P] 80% faster, 50% less memory, 0% loss in accuracy Llama finetuning                                                                                            | https://github.com/unslothai/unsloth                     |     204 | 2023-12-01 16:31:39 |
|                                                                                                                                                                  | https://github.com/danielhanchen/hyperlearn              |         |                     |
|                                                                                                                                                                  | https://github.com/unslothai/unsloth/blob/main/README.md |         |                     |
| [D] Bitter Lesson and Tree of Thoughts - Are techniques like ToT examples of using search or are they ignoring the bitter lesson by encoding humanlike learning? | https://arxiv.org/pdf/2309.15028.pdf                     |      36 | 2023-12-02 13:23:42 |
|                                                                                                                                                                  | https://arxiv.org/pdf/2303.05510.pdf                     |         |                     |
|                                                                                                                                                                  | https://arxiv.org/pdf/2305.10601.pdf                     |         |                     |